---
# YAML Front Matter：文章設定區塊
title: "跑一個本地端AI，呼應主權AI"
description: "寫新專案的人要讀很多東西，在AI領域發現有自己的資料或是透過離線，可以做到很多事情。之前測試過幾個中國的模型，用語方式都跟台灣有所不同。這次來使用台灣自己的AI，測試一下這個模型大概到什麼程度"
categories: ["LLM"]   # 這是您的分類，可以自己決定
tags: ["TAIDE","本地端AI"]           # 這是文章的標籤
---

這次使用2025年8月最新的模型Gemma-3-TAIDE-12b-Chat，測試的設備是Mac Mini M4 16G，第一次使用透過[TAIDE](https://taide.tw/)在[Hugging Face](https://huggingface.co/taide)的開源模型，透過爬梳文本得知這個模型是Google訓練，並且爬到2021年台灣的相關資料庫。

第一次測試發現需要25G記憶體才跑得起來，透過監控得知十分卡頓；透過Gemini問答排解問題是使用到較好的版本，改用Q4_K_M壓縮版本，就可以壓在執行8G左右跑起來。中文流暢度沒有問題，缺點是在長文對話後會延遲比較嚴重。透過輸入以下指令解決長文問題。
> /clear

1. 下載[Ollama](https://ollama.com/download/mac)
2. 終端機啟用測試，
3. 輸入啟用
>ollama run 輸入Hugging Face上面的位置及版本

### 使用回饋
意外的還可以，難以說明，但在中文掌握上比起Gemini有一些溫度。未來運用可以跑客服或是本地端的資料服務。
